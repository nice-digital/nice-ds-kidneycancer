{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nice-digital/nice-ds-literatureprocessing/blob/master/code/breast_cancer/preprocess_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnU47LawS_KM"
   },
   "source": [
    "# **Kidney Cancer Pre-Processing Colab**\n",
    "\n",
    "This notebook is the first stage in Breast cancer processing, and does the necessary pre-processing of the input data- title & abstracts\n",
    "\n",
    "Please name your data file input_data.csv (title column should be named 'Title' or 'title' and abstract column if present should be named 'Abstract' or 'abstract'), and upload it by pressing the upload button on the top left of the left sidebar. The results will appear in a folder named RESULTS. RESULTS folder will be automatically created by the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "rqAYettqat4V"
   },
   "outputs": [],
   "source": [
    "#@title Install Python packages { form-width: \"20%\" }\n",
    "\n",
    "#@markdown Please execute this cell by pressing the _Play_ button \n",
    "#@markdown on the left to download and import third-party software \n",
    "#@markdown in this Colab notebook. \n",
    "\n",
    "#@markdown This installs the software on the Colab \n",
    "#@markdown notebook in the cloud and not on your computer.\n",
    "from IPython.utils import io\n",
    "try:\n",
    "  with io.capture_output() as captured:\n",
    "    %shell pip install scispacy\n",
    "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_md-0.5.0.tar.gz\n",
    "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
    "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\n",
    "    %shell pip install pyLDAvis==2.1.2\n",
    "    %shell pip install import-ipynb\n",
    "    %shell pip install pandas\n",
    "    %shell pip install shutup\n",
    "   \n",
    "except subprocess.CalledProcessError:\n",
    "  print(captured)\n",
    "  raise\n",
    "import shutup\n",
    "shutup.please()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import spacy\n",
    "import scispacy\n",
    "import pandas as pd\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import csv\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "from spacy.matcher import Matcher\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    " # Load relevant Spacy models\n",
    "nlp = spacy.load(\"en_core_sci_md\")\n",
    "nlpDiseaseChem = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "nlpcancer = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "\n",
    "# Add the abbreviation pipe to the spacy pipeline.\n",
    "nlp.add_pipe(\"abbreviation_detector\")\n",
    "cpu_count = mp.cpu_count()\n",
    "\n",
    "pd. set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "UnkwogECa7pE"
   },
   "outputs": [],
   "source": [
    "#@title File settings to get started { form-width: \"20%\" }\n",
    "\n",
    "#@markdown Please ensure the input_data.csv is uploaded and execute this cell by pressing the _Play_ button \n",
    "#@markdown on the left \n",
    "DATA_PATH = 'input_data.csv'\n",
    "\n",
    "results_folder = 'RESULTS' \n",
    "RESULTS_FOLDER = results_folder     #***user input\n",
    "if not os.path.isdir(RESULTS_FOLDER):\n",
    "    os.makedirs(RESULTS_FOLDER)\n",
    "RESULTS_PATH = Path(RESULTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "1v4GpODgr79q"
   },
   "outputs": [],
   "source": [
    "#@title Read in input data { form-width: \"20%\" }\n",
    "lit_data = pd.read_csv(DATA_PATH)\n",
    "lit_data.rename(columns = {'Title':'title', 'Abstract': 'abstract'}, inplace = True)\n",
    "print(\"Number of studies in the original dataset: \" + str(lit_data.shape[0]))\n",
    "lit_data.drop_duplicates(subset=['title'], inplace=True)\n",
    "lit_data['title_orig'] = lit_data['title']\n",
    "lit_data['abstract_orig'] = lit_data['abstract']\n",
    "print(\"Number of studies in the dataset after de-dupe: \" + str(lit_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Kr-uAxApbrkV"
   },
   "outputs": [],
   "source": [
    "#@title Pre-process input data: Replace acronyms by its long form (do this before any case change/punctuation processing) { form-width: \"20%\" }\n",
    "def replace_acronyms(txt):\n",
    "  \"\"\" Replace the acronyms with it's long form\n",
    "    :param txt: txt which has acronyms\n",
    "    :return: txt with acronyms replaced with its long form or original txt if an exception occured\n",
    "  \"\"\"\n",
    "  try:\n",
    "    doc = nlp(txt)\n",
    "    altered_tok = [tok.text for tok in doc]\n",
    "    for abrv in doc._.abbreviations:\n",
    "      altered_tok[abrv.start] = str(abrv._.long_form)\n",
    "    full_txt = \" \".join(altered_tok)\n",
    "  except:\n",
    "    return (txt)\n",
    "  return(full_txt)\n",
    "\n",
    "with mp.Pool(cpu_count) as pool:\n",
    "  lit_data['title'] = pool.map(replace_acronyms, lit_data['title'])\n",
    "with mp.Pool(cpu_count) as pool:\n",
    "  lit_data['abstract'] = pool.map(replace_acronyms, lit_data['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Y-b7L3FRdSlW"
   },
   "outputs": [],
   "source": [
    "#@title Clone the SciLiteratureProcessing GITHub repo to access pre-processing code { form-width: \"20%\" }\n",
    "\n",
    "!git clone https://github.com/nice-digital/SciLiteratureProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "e3EkrXo9dg0h"
   },
   "outputs": [],
   "source": [
    "#@title This defines code which will be used for pre-processing, identifying study design/categories.\n",
    "\n",
    "%cd /content/SciLiteratureProcessing/code/\n",
    "\n",
    "# Function definitions to pre-process title and abstract\n",
    "%run -i \"text_preprocess.py\"\n",
    "\n",
    "# Function definitions for pattern matching\n",
    "%run -i \"text_patternmatch.py\"\n",
    "\n",
    "%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "8O81-LmWdpQF"
   },
   "outputs": [],
   "source": [
    "#@title SR & RCT pattern matching { form-width: \"20%\" }\n",
    "lit_data = preproc_title(lit_data) \n",
    "lit_data = preproc_abstract(lit_data)\n",
    "lit_data['Syst-Meta'] = lit_data.apply(match_studydesign_systematicrev, axis=1)\n",
    "lit_data['RCT'] = lit_data.apply(match_studydesign_RCT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_mCuuQ6O-yPn"
   },
   "outputs": [],
   "source": [
    "#@title Add valid entities not picked up by NER models- BC code, delete if not valid { form-width: \"20%\" }\n",
    "DISEASE_ENTS = ['triple negative breast cancer']\n",
    "CANCER_ENTS = ['mastectomy']\n",
    "DRUGS_ENTS = ['palbociclib', 'inetetamab', 'avelumab', 'camrelizumab','carvedilol', 'eryaspase ', 'imlunestrant', 'inavolisib', 'leucostim', 'alpelisib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "C7KaEQsAb0jD"
   },
   "outputs": [],
   "source": [
    "#@title Medical entity extraction { form-width: \"20%\" }\n",
    "def extract_entities(record):\n",
    "  \"\"\" Extract medical entities from the txt (title/abstract), results of three medical entity models are returned\n",
    "    :param record: a row in the dataframe\n",
    "    :return: fields which represent medical entities\n",
    "  \"\"\"\n",
    "  med_list = []\n",
    "  disease_list = []\n",
    "  chemical_list = []\n",
    "  ent_list = []\n",
    "  cancer_list = []\n",
    "  unique_disease_list = []\n",
    "  unique_chemical_list = []\n",
    "  unique_med_list = []\n",
    "  unique_ent_list = []\n",
    "  unique_cancer_list = []\n",
    "  unique_cancer_notmed_list = []\n",
    "  try:\n",
    "    #abstract = record[col]\n",
    "    abstract = record\n",
    "    doc_sci = nlp(abstract)\n",
    "    doc_diseasechem = nlpDiseaseChem(abstract) \n",
    "    doc_cancer = nlpcancer(abstract)\n",
    "    #displacy.render(doc_diseasechem,style='ent',jupyter=True)\n",
    "    #displacy.render(doc_cancer,style='ent',jupyter=True)\n",
    "    for ent in doc_sci.ents:  \n",
    "    '''\n",
    "      #Below code is BC specific. Delete once confirmed\n",
    "      if ent.text in DISEASE_ENTS:\n",
    "        med_list.append(ent.text)\n",
    "        disease_list.append(ent.text)\n",
    "        if (ent.text not in unique_med_list):\n",
    "          unique_med_list.append(ent.text)\n",
    "          unique_disease_list.append(ent.text)\n",
    "\n",
    "      if ent.text in DRUGS_ENTS:\n",
    "        med_list.append(ent.text)\n",
    "        chemical_list.append(ent.text)\n",
    "        if (ent.text not in unique_med_list):\n",
    "          unique_med_list.append(ent.text)\n",
    "          unique_chemical_list.append(ent.text)\n",
    "      \n",
    "      if ent.text in CANCER_ENTS:\n",
    "        cancer_list.append(ent.text)\n",
    "        if (ent.text not in unique_cancer_list):\n",
    "          unique_cancer_list.append(ent.text)\n",
    "    '''\n",
    "      ent_list.append(ent.text)   \n",
    "      if (ent.text not in unique_ent_list):\n",
    "        unique_ent_list.append(ent.text)\n",
    "    \n",
    "    for ent in doc_diseasechem.ents:\n",
    "      med_list.append(ent.text)\n",
    "      if (ent.text not in unique_med_list):\n",
    "        unique_med_list.append(ent.text)   \n",
    "      if ent.label_ == 'DISEASE':\n",
    "        disease_list.append(ent.text)\n",
    "        if (ent.text not in unique_disease_list):\n",
    "          unique_disease_list.append(ent.text)\n",
    "      if ent.label_ == 'CHEMICAL':\n",
    "        chemical_list.append(ent.text)\n",
    "        if (ent.text not in unique_chemical_list):\n",
    "          unique_chemical_list.append(ent.text)  \n",
    "      \n",
    "    for ent in doc_cancer.ents:\n",
    "      cancer_list.append(ent.text)\n",
    "      if (ent.text not in unique_cancer_list):\n",
    "        unique_cancer_list.append(ent.text)\n",
    "      if (ent.text not in unique_med_list):\n",
    "        unique_cancer_notmed_list.append(ent.text)\n",
    "    return pd.Series([med_list, disease_list, chemical_list, cancer_list, ent_list, unique_med_list, unique_disease_list, unique_chemical_list, unique_cancer_list, unique_cancer_notmed_list, unique_ent_list])\n",
    "  except Exception as e:\n",
    "    # Empty list will be returned\n",
    "    return pd.Series([med_list, disease_list, chemical_list, cancer_list, ent_list, unique_med_list, unique_disease_list, unique_chemical_list, unique_cancer_list, unique_cancer_notmed_list, unique_ent_list])\n",
    "\n",
    "with mp.Pool(cpu_count) as pool:\n",
    "  lit_data[['medTokens_title', 'med_disease_title', 'med_chem_title', 'cancerTokens_title','entTokens_title', 'uniqueMed_title', 'uniqueDisease_title','uniqueChemical_title','uniqueCancer_title', 'uniqueCancerNotmed_title', 'uniqueEnt_title']] = pool.map(extract_entities, lit_data['title'])\n",
    "with mp.Pool(cpu_count) as pool:\n",
    "  lit_data[['medTokens_abs', 'med_disease_abs', 'med_chem_abs', 'cancerTokens_abs','entTokens_abs', 'uniqueMed_abs', 'uniqueDisease_abs','uniqueChemical_abs','uniqueCancer_abs', 'uniqueCancerNotmed_abs', 'uniqueEnt_abs']] = pool.map(extract_entities, lit_data['abstract'])\n",
    "#lit_data[['medTokens_title', 'med_disease_title', 'med_chem_title', 'cancerTokens_title','entTokens_title', 'uniqueMed_title', 'uniqueDisease_title','uniqueChemical_title','uniqueCancer_title', 'uniqueCancerNotmed_title', 'uniqueEnt_title']] = lit_data.apply((lambda row: extract_entities(row, 'title')), axis = 1)\n",
    "#lit_data[['medTokens_abs', 'med_disease_abs', 'med_chem_abs', 'cancerTokens_abs','entTokens_abs', 'uniqueMed_abs', 'uniqueDisease_abs','uniqueChemical_abs','uniqueCancer_abs', 'uniqueCancerNotmed_abs', 'uniqueEnt_abs']] = lit_data.apply((lambda row: extract_entities(row, 'abstract')), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nYRGzIkx-oM1"
   },
   "outputs": [],
   "source": [
    "#@title utility function, delete if not needed\n",
    "# combine two lists and de-dup\n",
    "def exclude_duplicates(list):\n",
    "  return ([*set(list)])\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xj63kPFMCFc8"
   },
   "outputs": [],
   "source": [
    "#@title Write the results out { form-width: \"20%\" }\n",
    "lit_data.to_csv(RESULTS_PATH / \"preprocessed_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "gpUwKvBHn1HP"
   },
   "outputs": [],
   "source": [
    "#@title Write a tidy version of results { form-width: \"20%\" }\n",
    "lit_data['medTokens'] = lit_data['medTokens_title'] + lit_data['medTokens_abs']\n",
    "lit_data['medTokens_disease'] = lit_data['med_disease_title'] + lit_data['med_disease_abs']\n",
    "lit_data['unique_med_disease'] = lit_data['medTokens_disease'].apply(exclude_duplicates)\n",
    "lit_data['medTokens_chemical'] = lit_data['med_chem_title'] + lit_data['med_chem_abs']\n",
    "lit_data['unique_med_chemical'] = lit_data['medTokens_chemical'].apply(exclude_duplicates)\n",
    "lit_data['cancerTokens'] = lit_data['cancerTokens_title'] + lit_data['cancerTokens_abs']\n",
    "lit_data['entTokens'] = lit_data['entTokens_title'] + lit_data['entTokens_abs']\n",
    "lit_data['unique_cancer_med'] = lit_data['cancer_med_title'] + lit_data['cancer_med_abstract']\n",
    "lit_data['unique_cancer_med'] = lit_data['unique_cancer_med'].apply(exclude_duplicates)\n",
    "lit_data['unique_entTokens'] = lit_data['entTokens'].apply(exclude_duplicates)\n",
    "lit_data_subset = lit_data[['title', 'abstract', 'title_orig', 'abstract_orig', 'Syst-Meta', 'RCT', 'include','medTokens','medTokens_disease',\n",
    "                           'medTokens_chemical', 'cancerTokens', 'entTokens', 'unique_entTokens', 'unique_med_disease', 'unique_med_chemical', 'unique_cancer_med']]\n",
    "lit_data_subset.to_csv(RESULTS_PATH / \"preprocessed_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "q_KVH_NeiO9Y"
   },
   "outputs": [],
   "source": [
    "#@title Exclusion words/phrases for the cells after this one { form-width: \"20%\" }\n",
    "\n",
    "#@markdown Please execute this cell by pressing the _Play_ button \n",
    "#@markdown on the left\n",
    "\n",
    "# Below are the list of irrelevant words for entity model\n",
    "ENTITY_IRRELEVANT = []\n",
    "# Below are the list of irrelevant words for medical entity model\n",
    "MED_IRRELEVANT = ['breast', 'Cancer', 'Breast cancer', 'cancer', 'breast cancer', 'breast cancer ', 'cancer', 'cancers', 'breast cancers', 'objective(s', 'purpose(s', 'tumors', 'patients','patient', 'breast cancer patients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YNsaeBc2h7kw"
   },
   "outputs": [],
   "source": [
    "#@title Generate term frequencies and term clouds { form-width: \"20%\" }\n",
    "\n",
    "#@markdown Please execute this cell by pressing the _Play_ button on the left \n",
    "\n",
    "\n",
    "def analyse_termfreq(data_col, freq_fname, wordcloud_fname):\n",
    "   \"\"\" Word clouds and term frequencies\n",
    "    :param data_col: lit_data column to analyse\n",
    "    :param data_col: the column in the dataframe to analyse \n",
    "    :param freq_fname: filename of term freq excel\n",
    "    :param wordcloud_fname: filename of word cloud\n",
    "  \"\"\"\n",
    "  data = lit_data.loc[lit_data['include'] > 0] #only select breast cancer relevant includes\n",
    "  print(data.shape[0])\n",
    "  data = data[data_col]\n",
    "  data_list = list([a for b in data.tolist() for a in b])\n",
    "  l = []\n",
    "  for x in data_list:\n",
    "    if x not in MED_IRRELEVANT:\n",
    "      l.append(x)\n",
    "  s_counts = collections.Counter(l)\n",
    "  with open(RESULTS_PATH / freq_fname,'w') as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerows(s_counts.items())\n",
    "\n",
    "  wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = [',', 'cancer', 'cancers', 'Cancer'],\n",
    "                relative_scaling = 0.6,\n",
    "                prefer_horizontal=1,\n",
    "                min_font_size = 10)\n",
    "  \n",
    "  wordcloud.generate_from_frequencies(s_counts, max_font_size=300)\n",
    "  # Save the image in the img folder:\n",
    "  wordcloud.to_file(RESULTS_PATH / wordcloud_fname)\n",
    "  # plot the WordCloud image                      \n",
    "  plt.figure(figsize = (8, 8), facecolor = None)\n",
    "  plt.imshow(wordcloud)\n",
    "  plt.axis(\"off\")\n",
    "  plt.tight_layout(pad = 0)\n",
    "  plt.show()\n",
    "\n",
    "analyse_termfreq('unique_med_disease', 'termfreq_disease.csv', 'wordcloud_disease.png')\n",
    "analyse_termfreq('unique_med_chemical', 'termfreq_chemical.csv', 'wordcloud_chemical.png')\n",
    "analyse_termfreq('unique_cancer_med', 'termfreq_uniqueCancerMed.csv', 'wordcloud_uniqueCancerMed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "dxocsh-6ip54"
   },
   "outputs": [],
   "source": [
    "#@title Execute this to download the full RESULTS folder as a zip file { form-width: \"20%\" }\n",
    "\n",
    "#@markdown Optional to execute this cell. \n",
    "\n",
    "#@markdown A RESULTS.zip file will be generated on the left pane if you execute this cell\n",
    "!zip -r /content/RESULTS.zip /content/RESULTS"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOkZOjGmRJCbWM7ogITD9Bm",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
